{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explainable Sentiment Analysis - Interactive Demo\n",
        "\n",
        "This notebook demonstrates the explainable sentiment analysis system with interactive examples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from model import InterpretableSentimentClassifier, SentimentModelWrapper\n",
        "from explainability import (\n",
        "    IntegratedGradientsExplainer, SHAPLikeExplainer,\n",
        "    RationaleGenerator, CounterfactualGenerator\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_name = 'roberta-base'\n",
        "\n",
        "print(f\"Loading model: {model_name} on {device}\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = InterpretableSentimentClassifier(\n",
        "    model_name=model_name,\n",
        "    num_labels=3\n",
        ")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "wrapper = SentimentModelWrapper(model, tokenizer, device=device)\n",
        "print(\"Model loaded!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example: Basic Prediction and Explanation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \"I absolutely love this product! It's amazing and works perfectly.\"\n",
        "\n",
        "# Get prediction\n",
        "prediction = wrapper.predict_text(text)\n",
        "print(f\"Text: {text}\")\n",
        "print(f\"\\nPredicted Label: {prediction['label']}\")\n",
        "print(f\"Confidence: {prediction['confidence']:.2%}\")\n",
        "print(f\"\\nProbabilities:\")\n",
        "for label, prob in prediction['probabilities'].items():\n",
        "    print(f\"  {label}: {prob:.2%}\")\n",
        "\n",
        "# Get attributions\n",
        "ig_explainer = IntegratedGradientsExplainer(model, tokenizer, device=device)\n",
        "attributions = ig_explainer.get_attributions(text)\n",
        "\n",
        "# Display top contributing tokens\n",
        "token_scores = list(zip(attributions['tokens'], attributions['attributions']))\n",
        "token_scores.sort(key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "print(\"\\nTop Contributing Tokens:\")\n",
        "for token, score in token_scores[:10]:\n",
        "    direction = \"↑\" if score > 0 else \"↓\"\n",
        "    print(f\"{direction} '{token}': {score:+.3f}\")\n",
        "\n",
        "# Generate rationale\n",
        "rationale_gen = RationaleGenerator()\n",
        "rationale = rationale_gen.generate(\n",
        "    prediction['label'],\n",
        "    prediction['confidence'],\n",
        "    attributions,\n",
        "    prediction['probabilities']\n",
        ")\n",
        "\n",
        "print(f\"\\nRationale: {rationale}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
